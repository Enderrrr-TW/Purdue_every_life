{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIPS 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4351_trimmed_normalized_fps.xyz', '/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4370_trimmed_normalized_fps.xyz']\n",
      "[4.551, 4.489]\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "test_plot_ID=[4351,4370,4371,4390,4391,4410,4411,4430,4431]\n",
    "def train_test_split(test_plot_ID,output_name): # HIPS_2021\n",
    "    # test_plot_ID=[4360,4361,4380,4381,4400,4401,4420,4421,4440] # this one is the west of HIPS\n",
    "     # this is the east of HIPS\n",
    "    input_folder='/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps'\n",
    "    LAI=pd.read_csv('/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/LAI_LiDAR_date.csv',index_col='plot')\n",
    "    dataset={} \n",
    "    dataset['train']=dict()\n",
    "    dataset['test']={}\n",
    "    dataset['train']['path']=[]\n",
    "    dataset['train']['LAI']=[]\n",
    "    dataset['test']['path']=[]\n",
    "    dataset['test']['LAI']=[]\n",
    "    dates=os.listdir(input_folder)\n",
    "    for date in dates:\n",
    "        sub_dir=input_folder+'/'+date\n",
    "        if os.path.isdir(sub_dir)==False: continue\n",
    "        flist=os.listdir(sub_dir)\n",
    "        for f in flist:\n",
    "            fpath=sub_dir+'/'+f\n",
    "            plot_ID=int(f[9:13]) # for UAV\n",
    "            # plot_ID=int(f[17:21]) # for bp\n",
    "            if plot_ID in test_plot_ID:\n",
    "                dataset['test']['path'].append(fpath)\n",
    "                dataset['test']['LAI'].append(LAI.loc[plot_ID,str(date)])\n",
    "            else:\n",
    "                dataset['train']['path'].append(fpath)\n",
    "                dataset['train']['LAI'].append(LAI.loc[plot_ID,str(date)])\n",
    "    # val_plot_ID=[4359,4362,4379,4382,4399,4402,4419,4422,4439]\n",
    "    # train_plot_ID=[i for i in range(4351,4441)]\n",
    "    # train_plot_ID=list(set(train_plot_ID)-set(val_plot_ID)-set(test_plot_ID))\n",
    "    print(dataset['test']['path'][0:2])\n",
    "    print(dataset['test']['LAI'][0:2])\n",
    "    print(len(dataset['test']['path']))\n",
    "\n",
    "    with open(input_folder+'/'+output_name,'w') as output:\n",
    "        json.dump(dataset,output)\n",
    "train_test_split(test_plot_ID,'train_test_split.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 folds-straitified by inbred/hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4415, 4437, 4413, 4432, 4355, 4375, 4406, 4428, 4360, 4381]\n",
      "['/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4355_trimmed_normalized_fps.xyz', '/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4360_trimmed_normalized_fps.xyz']\n",
      "[4.238, 4.012]\n",
      "50\n",
      "-------------------\n",
      "[4396, 4418, 4370, 4379, 4364, 4392, 4407, 4430, 4411, 4422]\n",
      "['/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4364_trimmed_normalized_fps.xyz', '/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4370_trimmed_normalized_fps.xyz']\n",
      "[4.792, 4.489]\n",
      "50\n",
      "-------------------\n",
      "[4363, 4393, 4369, 4391, 4368, 4377, 4409, 4419, 4403, 4429]\n",
      "['/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4363_trimmed_normalized_fps.xyz', '/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4368_trimmed_normalized_fps.xyz']\n",
      "[3.689, 3.668]\n",
      "50\n",
      "-------------------\n",
      "[4352, 4386, 4397, 4438, 4367, 4376, 4356, 4387, 4412, 4435]\n",
      "['/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4352_trimmed_normalized_fps.xyz', '/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4356_trimmed_normalized_fps.xyz']\n",
      "[3.768, 4.063]\n",
      "50\n",
      "-------------------\n",
      "[4400, 4417, 4366, 4374, 4361, 4389, 4410, 4425]\n",
      "['/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4361_trimmed_normalized_fps.xyz', '/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4366_trimmed_normalized_fps.xyz']\n",
      "[3.968, 4.93]\n",
      "40\n",
      "-------------------\n",
      "[4402, 4431, 4362, 4380, 4359, 4394, 4404, 4423]\n",
      "['/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4359_trimmed_normalized_fps.xyz', '/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4362_trimmed_normalized_fps.xyz']\n",
      "[5.166, 3.768]\n",
      "40\n",
      "-------------------\n",
      "[4408, 4433, 4357, 4383, 4371, 4388, 4405, 4434]\n",
      "['/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4357_trimmed_normalized_fps.xyz', '/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4371_trimmed_normalized_fps.xyz']\n",
      "[4.786, 4.268]\n",
      "40\n",
      "-------------------\n",
      "[4353, 4378, 4395, 4426, 4358, 4373, 4401, 4421]\n",
      "['/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4353_trimmed_normalized_fps.xyz', '/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4358_trimmed_normalized_fps.xyz']\n",
      "[3.914, 4.396]\n",
      "40\n",
      "-------------------\n",
      "[4365, 4382, 4351, 4390, 4399, 4424, 4414, 4420]\n",
      "['/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4351_trimmed_normalized_fps.xyz', '/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4365_trimmed_normalized_fps.xyz']\n",
      "[4.551, 4.973]\n",
      "40\n",
      "-------------------\n",
      "[4372, 4385, 4416, 4427, 4398, 4436, 4354, 4384]\n",
      "['/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4354_trimmed_normalized_fps.xyz', '/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps/20210730/20210730_4372_trimmed_normalized_fps.xyz']\n",
      "[4.151, 3.788]\n",
      "40\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "fold0=[4415, 4437, 4413, 4432, 4355, 4375, 4406, 4428, 4360, 4381]\n",
    "fold1=[4396, 4418, 4370, 4379, 4364, 4392, 4407, 4430, 4411, 4422]\n",
    "fold2=[4363, 4393, 4369, 4391, 4368, 4377, 4409, 4419, 4403, 4429]\n",
    "fold3=[4352, 4386, 4397, 4438, 4367, 4376, 4356, 4387, 4412, 4435]\n",
    "fold4=[4400, 4417, 4366, 4374, 4361, 4389, 4410, 4425]\n",
    "fold5=[4402, 4431, 4362, 4380, 4359, 4394, 4404, 4423]\n",
    "fold6=[4408, 4433, 4357, 4383, 4371, 4388, 4405, 4434]\n",
    "fold7=[4353, 4378, 4395, 4426, 4358, 4373, 4401, 4421]\n",
    "fold8=[4365, 4382, 4351, 4390, 4399, 4424, 4414, 4420]\n",
    "fold9=[4372, 4385, 4416, 4427, 4398, 4436, 4354, 4384]\n",
    "folds=[fold0,fold1,fold2,fold3,fold4,fold5,fold6,fold7,fold8,fold9]\n",
    "for i in range(10):\n",
    "    test_plot_ID=folds[i]\n",
    "    print(test_plot_ID)\n",
    "    output_name=f'train_test_split_fold{i}.json'\n",
    "    train_test_split(test_plot_ID,output_name)\n",
    "    print('-------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validatioon set selection (just for testing, you don't need to run this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import re\n",
    "def validation_set_selector(root,k):\n",
    "    with open(root+'/'+f'train_test_split_fold{k}.json','r') as json_file:\n",
    "        data_dict=json.load(json_file)\n",
    "    date_list=[]\n",
    "    for i in range(len(data_dict['train']['path'])):\n",
    "        rlist=re.split('/',data_dict['train']['path'][i])\n",
    "        date_list.append(rlist[-2])\n",
    "        \n",
    "    skf=StratifiedKFold(n_splits=10,random_state=42,shuffle=True)\n",
    "    skf.get_n_splits(data_dict['train']['path'],date_list)\n",
    "    for train_index, valid_index in skf.split(data_dict['train']['path'],date_list):\n",
    "        return train_index,valid_index\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date:20210730,hi:hybrid\n",
      "date:20210730,hi:hybrid\n",
      "date:20210730,hi:hybrid\n",
      "date:20210730,hi:hybrid\n",
      "date:20210730,hi:inbred\n",
      "date:20210730,hi:inbred\n",
      "date:20210730,hi:inbred\n",
      "date:20210730,hi:inbred\n",
      "date:20210804,hi:hybrid\n",
      "date:20210804,hi:hybrid\n",
      "date:20210804,hi:hybrid\n",
      "date:20210804,hi:hybrid\n",
      "date:20210804,hi:inbred\n",
      "date:20210804,hi:inbred\n",
      "date:20210804,hi:inbred\n",
      "date:20210804,hi:inbred\n",
      "date:20210808,hi:hybrid\n",
      "date:20210808,hi:hybrid\n",
      "date:20210808,hi:hybrid\n",
      "date:20210808,hi:hybrid\n",
      "date:20210808,hi:inbred\n",
      "date:20210808,hi:inbred\n",
      "date:20210808,hi:inbred\n",
      "date:20210808,hi:inbred\n",
      "date:20210816,hi:hybrid\n",
      "date:20210816,hi:hybrid\n",
      "date:20210816,hi:hybrid\n",
      "date:20210816,hi:hybrid\n",
      "date:20210816,hi:inbred\n",
      "date:20210816,hi:inbred\n",
      "date:20210816,hi:inbred\n",
      "date:20210816,hi:inbred\n",
      "date:20210822,hi:hybrid\n",
      "date:20210822,hi:hybrid\n",
      "date:20210822,hi:hybrid\n",
      "date:20210822,hi:hybrid\n",
      "date:20210822,hi:inbred\n",
      "date:20210822,hi:inbred\n",
      "date:20210822,hi:inbred\n",
      "date:20210822,hi:inbred\n"
     ]
    }
   ],
   "source": [
    "def validation_set_selector(root,k):\n",
    "    with open(root+'/'+f'train_test_split_fold{k}.json','r') as json_file:\n",
    "        data_dict=json.load(json_file)\n",
    "    stratified_feature=[]\n",
    "    for i in range(len(data_dict['train']['path'])):\n",
    "        rlist=re.split('/',data_dict['train']['path'][i])\n",
    "        plot_ID=int(re.split('_',data_dict['train']['path'][i])[6])\n",
    "        if plot_ID<4395:\n",
    "            hi_temp=1\n",
    "        else:\n",
    "            hi_temp=0\n",
    "        stratified_feature.append(rlist[-2]+str(hi_temp))\n",
    "\n",
    "    skf=StratifiedKFold(n_splits=10,random_state=42,shuffle=True)\n",
    "    skf.get_n_splits(data_dict['train']['path'],stratified_feature)\n",
    "    for train_index, valid_index in skf.split(data_dict['train']['path'],stratified_feature):\n",
    "        return train_index,valid_index\n",
    "\n",
    "root='/home/tirgan/a/huan1577/Pointnet_Pointnet2_pytorch/data/UAV/HIPS_2021/trim_normalized_fps'\n",
    "k=0\n",
    "i,ii=validation_set_selector(root,k)\n",
    "with open(root+'/'+f'train_test_split_fold{k}.json','r') as json_file:\n",
    "    data_dict=json.load(json_file)\n",
    "for j in ii:\n",
    "    d=re.split('/',data_dict['train']['path'][j])[-2]\n",
    "    h=int(re.split('_',data_dict['train']['path'][j])[6])\n",
    "    if h<4395:\n",
    "        hh='hybrid'\n",
    "    else:\n",
    "        hh='inbred'\n",
    "    print(f'date:{d},hi:{hh}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4640d119058903d111d18d7f603b646b5be370cbe1b78cd57f1e9112144caf9e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('torcher3d2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
